docker ps

# 1ï¸âƒ£ Supprimer les anciens conteneurs interrompus

docker-compose down

# 2ï¸âƒ£ Supprimer les anciennes images partielles

docker image prune -a -f

# 3ï¸âƒ£ Relancer le cluster

docker-compose up -d

docker pull bde2020/hadoop-namenode

# ğŸ§  Projet Big Data Cluster avec Docker

## Hadoop | Spark | Hive | PostgreSQL | Apache NiFi

---

## ğŸ—ï¸ Introduction

Dans le cadre de mon apprentissage en **IngÃ©nierie des DonnÃ©es**, jâ€™ai mis en place un **cluster Big Data** complet basÃ© sur **Docker**.  
Lâ€™objectif est de **simuler un environnement distribuÃ©** similaire Ã  un cluster de production, permettant le **stockage, le traitement et lâ€™analyse de grandes volumÃ©tries de donnÃ©es**.

Ce cluster comprend :

- **Hadoop (HDFS)** pour le stockage distribuÃ© des donnÃ©es.
- **Apache Spark** pour le calcul et le traitement en parallÃ¨le.
- **Apache Hive** pour lâ€™interrogation SQL des donnÃ©es sur HDFS.
- **PostgreSQL** servant de base de mÃ©tadonnÃ©es pour Hive.
- **Apache NiFi** pour lâ€™ingestion et lâ€™orchestration des flux de donnÃ©es.

---

## ğŸ¯ Objectifs du projet

- Mettre en place un **cluster Big Data multi-nÅ“uds** (1 master, 2 slaves) via **Docker Compose**.
- IntÃ©grer les **composants essentiels de lâ€™Ã©cosystÃ¨me Hadoop** (HDFS, Hive, Spark).
- Automatiser le dÃ©ploiement et la configuration des services.
- Faciliter la crÃ©ation dâ€™un **pipeline de donnÃ©es complet** : ingestion â†’ stockage â†’ traitement â†’ visualisation.

---

## ğŸ§© Architecture globale

### ğŸ”¹ Vue dâ€™ensemble du cluster

                 +-----------------------------+
                 |        Master Node          |
                 |-----------------------------|
                 |  Hadoop NameNode            |
                 |  Spark Master               |
                 |  Hive + PostgreSQL Metastore|
                 |  Apache NiFi                |
                 +-----------------------------+
                           |
       -------------------------------------------------
       |                                               |
        +--------------------+ +--------------------+
        | DataNode 1 | | DataNode 2 |
        |--------------------| |--------------------|
        | Hadoop Datanode | | Hadoop Datanode |
        | Spark Worker | | Spark Worker |
        +--------------------+ +--------------------+

---

## âš™ï¸ Technologies utilisÃ©es

| Outil              | RÃ´le                 | Description                                                                                    |
| ------------------ | -------------------- | ---------------------------------------------------------------------------------------------- |
| **Hadoop (HDFS)**  | Stockage distribuÃ©   | DÃ©coupe et rÃ©partit les fichiers sur plusieurs nÅ“uds pour tolÃ©rance aux pannes et scalabilitÃ©. |
| **Spark**          | Traitement distribuÃ© | ExÃ©cute les calculs Ã  grande Ã©chelle en mÃ©moire, plus rapide que MapReduce.                    |
| **Hive**           | Interrogation SQL    | Fournit une interface SQL au-dessus dâ€™HDFS pour manipuler les donnÃ©es facilement.              |
| **PostgreSQL**     | MÃ©tastore Hive       | Contient les mÃ©tadonnÃ©es des tables Hive (schÃ©mas, partitions, etc.).                          |
| **NiFi**           | Ingestion de donnÃ©es | Permet de capturer, transformer et charger les donnÃ©es depuis diverses sources.                |
| **Docker Compose** | Orchestration        | Permet de lancer et connecter tous les services avec une seule commande.                       |

---

## ğŸ§± Structure du cluster Docker

### ğŸ“ Arborescence du projet
