Voici un **README.md complet**, professionnel, clair et parfait pour ton GitHub ou ton rendu en tant que consultant Big Data.
Il suit une structure standard utilisÃ©e dans les vrais projets en entreprise.

---

# âœ… **README.md â€” Cluster Big Data avec Docker**

*(Copie-colle directement dans ton fichier `README.md`)*

---

```md
# ğŸš€ Cluster Big Data avec Docker  
### Hadoop + Spark + Hive + PostgreSQL + Apache NiFi  
### Architecture : 1 Master + 2 Slaves

---

## ğŸ“Œ 1. Introduction

Ce projet met en place un **cluster Big Data complet** basÃ© sur Docker, intÃ©grant :

- **Hadoop (HDFS + YARN)** â€” Stockage distribuÃ© et exÃ©cution des jobs  
- **Spark** â€” Traitement distribuÃ© en mÃ©moire  
- **Hive** â€” EntrepÃ´t de donnÃ©es avec interface SQL  
- **Metastore PostgreSQL** â€” MÃ©tadonnÃ©es Hive  
- **Apache NiFi** â€” ETL et ingestion de donnÃ©es  
- **3 nÅ“uds** : 1 Master + 2 Slaves

Lâ€™objectif est dâ€™obtenir un environnement complet pour :
- DÃ©veloppement
- Formation / dÃ©monstration Big Data
- POC Data Engineering
- Ingestion â†’ Stockage â†’ Traitement â†’ Consultation SQL

---

## ğŸ“‚ 2. Architecture du Cluster

```

```
                +------------------------+
                |       PostgreSQL        |
                |   Hive Metastore DB     |
                +------------+------------+
                             |
                 +-----------v-----------+
                 |     Hive Metastore    |
                 +-----------+-----------+
                             |
            +----------------+----------------+
            |                                 |
   +--------v--------+               +--------v--------+
   |     Master      |               |     Apache NiFi  |
   |------------------|               -------------------
   | Hadoop NameNode  |
   | YARN ResourceMgr |
   | Spark Master     |
   | HiveServer2      |
   +--------+---------+
            |
```

+-------------+----------------------------+
|                                          |
+---v---+                                 +---v---+
| Slave1|                                 | Slave2|
|-------|                                 |-------|
|DataNode|                                |DataNode|
|SparkWrk|                                |SparkWrk|
+-------+                                 +--------+

```

---

## ğŸ“ 3. Structure du Projet

```

bigdata-cluster/
â”‚
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ hadoop/
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ core-site.xml
â”‚       â”œâ”€â”€ hdfs-site.xml
â”‚       â”œâ”€â”€ yarn-site.xml
â”‚       â””â”€â”€ mapred-site.xml
â”‚
â”œâ”€â”€ hive/
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ hive-site.xml
â”‚       â””â”€â”€ metastore-site.xml
â”‚
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ spark-defaults.conf
â”‚
â”œâ”€â”€ nifi/
â”‚   â””â”€â”€ config/
â”‚
â””â”€â”€ README.md

````

---

## ğŸ› ï¸ 4. PrÃ©requis

- Docker Desktop â‰¥ 4.x
- Docker Compose â‰¥ v2
- 8 GB RAM minimum
- 20+ GB de stockage libre

---

## ğŸš€ 5. DÃ©marrage du Cluster

### Ã‰tape 1 â€” Formater le NameNode
(Docker oblige, premiÃ¨re initialisation obligatoire)

```bash
docker-compose up -d master
docker exec -it master hdfs namenode -format -force
````

### Ã‰tape 2 â€” DÃ©marrer tout le cluster

```bash
docker-compose up -d
```

---

## ğŸ” 6. Interfaces Web

| Service              | URL                                            |
| -------------------- | ---------------------------------------------- |
| Hadoop NameNode UI   | [http://localhost:9870](http://localhost:9870) |
| YARN ResourceManager | [http://localhost:8088](http://localhost:8088) |
| Spark Master UI      | [http://localhost:4040](http://localhost:4040) |
| HiveServer2          | JDBC Port 10000                                |
| NiFi Web UI          | [http://localhost:8080](http://localhost:8080) |

---

## ğŸ§ª 7. VÃ©rifications & Tests

### âœ” Test HDFS

```bash
docker exec -it master hdfs dfs -ls /
docker exec -it master hdfs dfs -mkdir /user
```

### âœ” Test Spark

```bash
docker exec -it master spark-submit \
  --class org.apache.spark.examples.SparkPi \
  /spark/examples/jars/spark-examples*.jar 10
```

### âœ” Test Hive (avec Beeline)

```bash
docker exec -it master beeline -u jdbc:hive2://master:10000 \
  -n hive -p hive \
  -e "SHOW DATABASES;"
```

CrÃ©er une table :

```sql
CREATE TABLE test (id INT, name STRING);
```

### âœ” Test NiFi

* AccÃ©der Ã  **[http://localhost:8080](http://localhost:8080)**
* Importer un template
* ExÃ©cuter un flux (ex : ingest â†’ HDFS â†’ Hive)

---

## ğŸ§± 8. Fonctionnement des Services

### ğŸ”µ Master Node

* NameNode
* ResourceManager
* Spark Master
* HiveServer2

### ğŸ”µ Slaves

* DataNode
* NodeManager
* Spark Worker

### ğŸ”µ PostgreSQL

* Base de mÃ©tadonnÃ©es Hive

### ğŸ”µ Hive Metastore

* Service intermÃ©diaire entre Hive et PostgreSQL

### ğŸ”µ Apache NiFi

* Ingestion / ETL automatisÃ©e

---

## ğŸ”§ 9. Administration du Cluster

### Logs dâ€™un service

```bash
docker logs master -f
```

### RedÃ©marrer un service

```bash
docker-compose restart slave2
```

### ArrÃªter tout

```bash
docker-compose down
```

### Supprimer volumes (nettoyage complet)

```bash
docker-compose down -v
```

---

## ğŸ“Œ 10. AmÃ©liorations possibles

* Ajouter Kafka + Zookeeper
* Ajouter Airflow (orchestration)
* IntÃ©grer Grafana + Prometheus pour monitoring
* Ajouter Superset ou Metabase pour BI
* DÃ©ployer sur Kubernetes (K8s)

---

## ğŸ“œ 11. Licence

Libre d'utilisation pour l'Ã©ducation, la formation, la dÃ©monstration et les POC Data Engineering.

---

## âœ¨ 12. Auteur

Projet rÃ©alisÃ© par **Abdoul Salam Diallo**
Ã‰tudiant M1 | Data Engineering | Big Data & Cloud Computing
UFR SET â€” UniversitÃ© Iba Der Thiam de ThiÃ¨s

---

```

---

# ğŸ‰ Si tu veux, je peux aussi te gÃ©nÃ©rer :

âœ… un **schÃ©ma PNG** de lâ€™architecture  
âœ… un **README version professionnelle consultant (PDF)**  
âœ… un **PowerPoint prÃªt Ã  prÃ©senter le projet**  

Dis-moi ce que tu veux.
```
