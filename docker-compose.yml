#version: "3.8"

# ============================================================
#               CLUSTER BIG DATA COMPLET
#    Hadoop + Spark + Hive + PostgreSQL + Nifi
#               Master + 2 Slaves
# ============================================================

services:
  # ============================================================
  # 1) BASE DE DONNÉES POSTGRESQL POUR LE METASTORE HIVE
  # ------------------------------------------------------------
  # Hive doit stocker les métadonnées des tables dans une base SQL.
  # Ici nous utilisons PostgreSQL (le plus utilisé en production).
  # ============================================================
  metastore-db:
    image: postgres:13
    container_name: metastore-db
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    ports:
      - "5433:5432" # permet d'accéder à PostgreSQL depuis la machine hôte
    volumes:
      - metastore-data:/var/lib/postgresql/data
    networks:
      - bigdata-net

  # ============================================================
  # 2) HIVE METASTORE SERVICE
  # ------------------------------------------------------------
  # Service indispensable qui communique entre Hive et PostgreSQL.
  # ============================================================
  hive-metastore:
    image: bitsondatadev/hive-metastore:latest
    container_name: hive-metastore
    environment:
      METASTORE_DB_HOSTNAME: metastore-db
      METASTORE_TYPE: postgres
      METASTORE_DB_PORT: 5432
    ports:
      - "9083:9083"
    volumes:
      - ./hive/config:/opt/hive/conf
    depends_on:
      - metastore-db
    networks:
      - bigdata-net

  # ============================================================
  # 3) MASTER NODE
  # ------------------------------------------------------------
  # Ce conteneur joue plusieurs rôles :
  #  - Hadoop Namenode (gère HDFS)
  #  - Hadoop ResourceManager (gestion des jobs YARN)
  #  - Spark Master
  #  - HiveServer2 (interaction avec Hive)
  #
  # C’est le cœur du cluster Big Data.
  # ============================================================
  master:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: master
    privileged: true
    environment:
      CLUSTER_NAME: "bigdata-cluster"
    ports:
      - "9870:9870" # Hadoop Namenode Web UI
      - "8088:8088" # YARN Resource Manager Web UI
      - "7077:7077" # Spark Master
      - "4040:4040" # Spark UI
      - "10000:10000" # HiveServer2 JDBC
    volumes:
      - ./hadoop/config:/etc/hadoop
      - ./hive/config:/opt/hive/conf
      - ./spark/config:/spark/conf
      - namenode-data:/hadoop/dfs/name
    depends_on:
      - hive-metastore
    networks:
      - bigdata-net

  # ============================================================
  # 4) SLAVE 1
  # ------------------------------------------------------------
  # Worker Hadoop + Worker Spark.
  # Exécute des tâches distribuées.
  # ============================================================
  slave1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: slave1
    privileged: true
    volumes:
      - ./hadoop/config:/etc/hadoop
      - datanode1-data:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "master:9870"
    networks:
      - bigdata-net
    depends_on:
      - master

  # ============================================================
  # 5) SLAVE 2
  # ------------------------------------------------------------
  # Identique à SLAVE 1
  # ============================================================
  slave2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: slave2
    privileged: true
    volumes:
      - ./hadoop/config:/etc/hadoop
      - datanode2-data:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "master:9870"
    networks:
      - bigdata-net
    depends_on:
      - master

  # ============================================================
  # 6) APACHE NIFI
  # ------------------------------------------------------------
  # Nifi est utilisé pour l'ingestion, l'automatisation et l'orchestration
  # des flux de données (IoT, logs, API, fichiers, etc.).
  # ============================================================
  nifi:
    image: apache/nifi:latest
    container_name: nifi
    ports:
      - "8080:8080" # Interface Web Nifi
    environment:
      NIFI_WEB_HTTP_PORT: 8080
    volumes:
      - ./nifi/config:/opt/nifi/nifi-current/conf
    networks:
      - bigdata-net

# ============================================================
#                  DECLARATION DES VOLUMES
# ============================================================
volumes:
  metastore-data:
  namenode-data:
  datanode1-data:
  datanode2-data:

# ============================================================
#                  CONFIGURATION DU RÉSEAU
# ============================================================
networks:
  bigdata-net:
    driver: bridge
